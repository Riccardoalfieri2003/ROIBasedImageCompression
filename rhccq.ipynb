{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ae8be3",
   "metadata": {},
   "source": [
    "# Region-Based Hierarchical Clustering Color Quantization (RHCCQ)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "RHCCQ is an adaptive image compression system that prioritizes visual quality in important regions while aggressively compressing less significant areas. Unlike standard compression methods, RHCCQ uses ROI detection to identify critical image regions and applies hierarchical color clustering to reduce colors without losing important details.\n",
    "\n",
    "## How It Works\n",
    "\n",
    "1. **ROI Detection**: Identifies important regions using edge density analysis\n",
    "2. **Region Segmentation**: Divides image into ROI (high quality) and non-ROI (low quality)\n",
    "3. **SubRegion Segmentation**: Each ROI and non-ROI gets divided in sub-regions\n",
    "4. **Hierarchical Clustering**: Groups similar colors while preserving important variations\n",
    "5. **Matrix Encoding**: Stores compressed color indices and optimized color palettes\n",
    "5. **File Output**: Creates .rhccq files with region information and compressed data\n",
    "\n",
    "## Technical Advantages\n",
    "\n",
    "- **Better Detail Preservation**: Hierarchical clustering reduces color banding artifacts\n",
    "- **Adaptive Bit Allocation**: More bits allocated to important regions\n",
    "- **Configurable Trade-offs**: Users balance quality vs. compression based on application needs\n",
    "- **Novel Approach**: Combines ROI awareness with advanced color quantization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73476f6",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "The following code shows the whole process of the compression by using a famous image for Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef96fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions to plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_border_stages(intensity_borders, binary_borders, \n",
    "                       binary_thin_bordersless, noiseless_binary_borders,\n",
    "                       pre_connected, connected, figsize=(16, 10)):\n",
    "    \"\"\"\n",
    "    Plot all border processing stages in a 2x3 grid.\n",
    "    \"\"\"\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
    "    \n",
    "    # Flatten axes for easy indexing\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Plot each image with appropriate colormap\n",
    "    images = [\n",
    "        (intensity_borders, \"Intensity Borders\", \"gray\"),\n",
    "        (binary_borders, \"Binary Borders\", \"gray\"),\n",
    "        (binary_thin_bordersless, \"Thinned Borders\", \"gray\"),\n",
    "        (noiseless_binary_borders, \"Noiseless Borders\", \"gray\"),\n",
    "        (pre_connected, \"Pre-Connected\", \"gray\"),\n",
    "        (connected, \"Final Connected\", \"gray\")\n",
    "    ]\n",
    "    \n",
    "    for ax, (img, title, cmap) in zip(axes, images):\n",
    "        # Handle binary vs intensity images\n",
    "        if img.dtype == bool or img.max() == 1:\n",
    "            ax.imshow(img, cmap=cmap, vmin=0, vmax=1)\n",
    "        else:\n",
    "            ax.imshow(img, cmap=cmap)\n",
    "        \n",
    "        ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add image stats\n",
    "        if img.dtype == bool:\n",
    "            stats = f\"True: {img.sum():,}\\nFalse: {(~img).sum():,}\"\n",
    "        else:\n",
    "            stats = f\"Min: {img.min():.1f}\\nMax: {img.max():.1f}\\nMean: {img.mean():.3f}\"\n",
    "        \n",
    "        # Add stats in top-left corner\n",
    "        ax.text(0.02, 0.98, stats,\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=9,\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.suptitle(\"Border Processing Pipeline\", fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_region_processing_pipeline(denoised, border_mask, protected_image, \n",
    "                                   bridged_image, closed_regions, cleaned_image, \n",
    "                                   region_map, figsize=(18, 10)):\n",
    "    \"\"\"\n",
    "    Plot the region processing pipeline in a 3x3 grid (with one empty spot).\n",
    "    \"\"\"\n",
    "    # Create subplots - 3x3 grid\n",
    "    fig, axes = plt.subplots(3, 3, figsize=figsize)\n",
    "    \n",
    "    # Images and their titles\n",
    "    images = [\n",
    "        denoised,\n",
    "        border_mask,\n",
    "        protected_image,\n",
    "        bridged_image,\n",
    "        closed_regions,\n",
    "        cleaned_image,\n",
    "        region_map\n",
    "    ]\n",
    "    \n",
    "    titles = [\n",
    "        \"1. Denoised Borders\",\n",
    "        \"2. Border Mask\", \n",
    "        \"3. Protected Image\",\n",
    "        \"4. Bridged Gaps\",\n",
    "        \"5. Morphologically Closed\",\n",
    "        \"6. Cleaned Regions\",\n",
    "        \"7. Final Region Map\"\n",
    "    ]\n",
    "    \n",
    "    descriptions = [\n",
    "        \"Noise removed from binary borders\",\n",
    "        \"Mask of detected border pixels\",\n",
    "        \"Original image with border protection\",\n",
    "        \"Small gaps bridged for connectivity\",\n",
    "        \"After morphological closing operations\",\n",
    "        \"Small regions filtered out\",\n",
    "        \"Final ROI (white) / non-ROI (black) map\"\n",
    "    ]\n",
    "    \n",
    "    # Plot each image\n",
    "    for idx, (img, title, desc) in enumerate(zip(images, titles, descriptions)):\n",
    "        row = idx // 3\n",
    "        col = idx % 3\n",
    "        \n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        # Choose colormap based on content\n",
    "        if 'region map' in title.lower() or 'mask' in title.lower():\n",
    "            # Binary/border images\n",
    "            if img.dtype == bool:\n",
    "                ax.imshow(img, cmap='gray_r', vmin=0, vmax=1)  # gray_r for white=borders\n",
    "            else:\n",
    "                ax.imshow(img, cmap='gray_r')\n",
    "        elif 'image' in title.lower():\n",
    "            # Color images\n",
    "            if len(img.shape) == 3 and img.shape[2] == 3:\n",
    "                ax.imshow(img)\n",
    "            else:\n",
    "                ax.imshow(img, cmap='gray')\n",
    "        else:\n",
    "            # Default to grayscale\n",
    "            ax.imshow(img, cmap='gray')\n",
    "        \n",
    "        ax.set_title(title, fontsize=12, fontweight='bold', color='darkgreen')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add statistics\n",
    "        stats_text = f\"{desc}\\n\\n\"\n",
    "        \n",
    "        if img.dtype == bool or np.max(img) <= 1:\n",
    "            # Binary image stats\n",
    "            true_count = np.sum(img)\n",
    "            total_pixels = img.size\n",
    "            percentage = (true_count / total_pixels) * 100\n",
    "            \n",
    "            if 'region' in title.lower():\n",
    "                stats_text += f\"ROI: {true_count:,} px\\n\"\n",
    "                stats_text += f\"({percentage:.1f}% of image)\"\n",
    "            else:\n",
    "                stats_text += f\"Edges: {true_count:,} px\\n\"\n",
    "                stats_text += f\"({percentage:.2f}%)\"\n",
    "        elif len(img.shape) == 2:\n",
    "            # Grayscale image stats\n",
    "            stats_text += f\"Range: [{img.min():.0f}, {img.max():.0f}]\\n\"\n",
    "            stats_text += f\"Mean: {img.mean():.1f}\"\n",
    "        else:\n",
    "            # Color image stats\n",
    "            stats_text += f\"Shape: {img.shape}\"\n",
    "        \n",
    "        # Add stats box\n",
    "        ax.text(0.02, 0.98, stats_text,\n",
    "                transform=ax.transAxes,\n",
    "                fontsize=9,\n",
    "                verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.9))\n",
    "    \n",
    "    # Hide the last two empty subplots (8th and 9th)\n",
    "    axes[2, 1].axis('off')\n",
    "    axes[2, 2].axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Region Processing Pipeline - From Borders to ROI Map\", \n",
    "                 fontsize=16, fontweight='bold', y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_subregions(bbox_region,bbox_mask,subregions_segments,segment_boundaries):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    # Debug visualization\n",
    "    print(f\"\\n=== DEBUG: SLIC/Watershed Segments ===\")\n",
    "    print(f\"bbox_region shape: {bbox_region.shape}\")\n",
    "    print(f\"bbox_mask shape: {bbox_mask.shape}\")\n",
    "    print(f\"Segments shape: {subregions_segments.shape}\")\n",
    "    print(f\"Unique segment IDs: {np.unique(subregions_segments)}\")\n",
    "\n",
    "    # Create a colormap for segments - SIMPLE FIX\n",
    "    num_segments = len(np.unique(subregions_segments))\n",
    "    colors = plt.colormaps['tab20'].resampled(num_segments)\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "    # 1. Original bbox region\n",
    "    axes[0, 0].imshow(bbox_region)\n",
    "    axes[0, 0].set_title('Original Region')\n",
    "    axes[0, 0].axis('off')\n",
    "\n",
    "    # 2. Mask overlay\n",
    "    axes[0, 1].imshow(bbox_region)\n",
    "    mask_overlay = np.zeros((*bbox_mask.shape, 4))\n",
    "    mask_overlay[bbox_mask] = [1, 0, 0, 0.3]  # Red overlay\n",
    "    mask_overlay[~bbox_mask] = [0, 0, 0, 0]  # Transparent\n",
    "    axes[0, 1].imshow(mask_overlay)\n",
    "    axes[0, 1].set_title('Region Mask (red)')\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "    # 3. Segments visualization\n",
    "    segments_display = np.zeros((*subregions_segments.shape, 3))\n",
    "    for seg_id in np.unique(subregions_segments):\n",
    "        if seg_id == 0:  # Background\n",
    "            continue\n",
    "        mask = subregions_segments == seg_id\n",
    "        color = colors(seg_id % colors.N)[:3]  # RGB only\n",
    "        segments_display[mask] = color\n",
    "\n",
    "    axes[0, 2].imshow(segments_display)\n",
    "    axes[0, 2].set_title(f'Segments ({num_segments-1} segments)')\n",
    "    axes[0, 2].axis('off')\n",
    "\n",
    "    # 4. Segments WITH mask boundary\n",
    "    axes[1, 0].imshow(segments_display)\n",
    "    # Draw mask boundary\n",
    "    from skimage.segmentation import find_boundaries\n",
    "    mask_boundary = find_boundaries(bbox_mask, mode='inner')\n",
    "    y, x = np.where(mask_boundary)\n",
    "    axes[1, 0].scatter(x, y, c='red', s=1, alpha=0.5)\n",
    "    axes[1, 0].set_title('Segments + Mask Boundary')\n",
    "    axes[1, 0].axis('off')\n",
    "\n",
    "    # 5. Problematic segments (outside mask)\n",
    "    problematic_mask = np.zeros_like(bbox_mask, dtype=bool)\n",
    "    for seg_id in np.unique(subregions_segments):\n",
    "        if seg_id == 0:\n",
    "            continue\n",
    "        segment_mask = subregions_segments == seg_id\n",
    "        outside_mask = segment_mask & ~bbox_mask\n",
    "        if np.any(outside_mask):\n",
    "            problematic_mask = problematic_mask | outside_mask\n",
    "\n",
    "    axes[1, 1].imshow(bbox_region)\n",
    "    if np.any(problematic_mask):\n",
    "        problematic_overlay = np.zeros((*problematic_mask.shape, 4))\n",
    "        problematic_overlay[problematic_mask] = [1, 0, 0, 0.7]  # Bright red\n",
    "        axes[1, 1].imshow(problematic_overlay)\n",
    "        axes[1, 1].set_title(f'Problem: {np.sum(problematic_mask)} pixels outside mask')\n",
    "    else:\n",
    "        axes[1, 1].set_title('Good: No pixels outside mask')\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "    # 6. Boundaries visualization\n",
    "    axes[1, 2].imshow(bbox_region)\n",
    "    for boundary_info in segment_boundaries:\n",
    "        seg_id = boundary_info['segment_id']\n",
    "        boundary_coords = boundary_info['boundary_coords']\n",
    "        \n",
    "        if len(boundary_coords) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Convert to numpy array for plotting\n",
    "        boundary_array = np.array(boundary_coords)\n",
    "        \n",
    "        # Get color for this segment\n",
    "        color = colors(seg_id % colors.N)[:3]\n",
    "        \n",
    "        # Plot boundary\n",
    "        axes[1, 2].plot(boundary_array[:, 1], boundary_array[:, 0], \n",
    "                    color=color, linewidth=1.5, alpha=0.8)\n",
    "        \n",
    "        # Label segment ID\n",
    "        if len(boundary_array) > 0:\n",
    "            centroid = np.mean(boundary_array, axis=0)\n",
    "            axes[1, 2].text(centroid[1], centroid[0], str(seg_id),\n",
    "                        color='white', fontsize=8, fontweight='bold',\n",
    "                        ha='center', va='center',\n",
    "                        bbox=dict(boxstyle='round,pad=0.2', \n",
    "                                    facecolor=color, alpha=0.7))\n",
    "\n",
    "    axes[1, 2].set_title(f'Boundaries ({len(segment_boundaries)} segments)')\n",
    "    axes[1, 2].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print statistics\n",
    "    print(f\"\\n=== SEGMENT STATISTICS ===\")\n",
    "    print(f\"Total segments: {num_segments - 1} (excluding background 0)\")\n",
    "\n",
    "    problematic_segments = []\n",
    "    for seg_id in np.unique(subregions_segments):\n",
    "        if seg_id == 0:\n",
    "            continue\n",
    "        \n",
    "        segment_mask = subregions_segments == seg_id\n",
    "        total_pixels = np.sum(segment_mask)\n",
    "        inside_pixels = np.sum(segment_mask & bbox_mask)\n",
    "        outside_pixels = np.sum(segment_mask & ~bbox_mask)\n",
    "        \n",
    "        if outside_pixels > 0:\n",
    "            problematic_segments.append(seg_id)\n",
    "            print(f\"Segment {seg_id}: {inside_pixels} inside, {outside_pixels} outside ({outside_pixels/total_pixels*100:.1f}% outside)\")\n",
    "        else:\n",
    "            print(f\"Segment {seg_id}: {inside_pixels} inside, fully within mask\")\n",
    "\n",
    "    if problematic_segments:\n",
    "        print(f\"\\nâš ï¸  PROBLEM: {len(problematic_segments)} segments extend outside mask!\")\n",
    "    else:\n",
    "        print(f\"\\nâœ“ GOOD: All segments are within mask\")\n",
    "\n",
    "    # Also check boundary extraction\n",
    "    print(f\"\\n=== BOUNDARY EXTRACTION ===\")\n",
    "    print(f\"Extracted boundaries for {len(segment_boundaries)} segments\")\n",
    "    for i, boundary_info in enumerate(segment_boundaries[:5]):  # Show first 5\n",
    "        print(f\"  Segment {boundary_info['segment_id']}: {boundary_info['num_points']} boundary points, area={boundary_info['area']}\")\n",
    "\n",
    "    \n",
    "\n",
    "def show_reconstruction(seg_compression, seg_idx,segment_image_cropped,top_left_abs_row,top_left_abs_col):\n",
    "        \n",
    "        from decoder.uncompression.uncompression import partial_decompress_color_quantization\n",
    "\n",
    "        reconstruction_result = partial_decompress_color_quantization(\n",
    "            seg_compression,\n",
    "        )\n",
    "\n",
    "\n",
    "        # ==============================================\n",
    "        # 4. VISUALIZE COMPARISON WITH STATS\n",
    "        # ==============================================\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"SEGMENT {seg_idx+1} - COLOR QUANTIZATION RESULTS\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        # Get stats from compression\n",
    "        h, w, _ = segment_image_cropped.shape\n",
    "        original_size = h * w * 3\n",
    "        compressed_size = seg_compression['compressed_size']\n",
    "        compression_ratio = seg_compression['compression_ratio']\n",
    "        psnr = seg_compression['psnr']\n",
    "        n_colors = seg_compression['compressed_colors']\n",
    "\n",
    "        # Print stats in a clean format\n",
    "        print(f\"Segment {seg_idx+1} Summary:\")\n",
    "        print(f\"  Shape: {h}x{w}\")\n",
    "        print(f\"  Top-left: {top_left_abs_row, top_left_abs_col}\")\n",
    "        print(f\"  Colors in palette: {n_colors}\")\n",
    "        print(f\"  Original size: {original_size:,} bytes\")\n",
    "        print(f\"  Compressed size: {compressed_size:,} bytes\")\n",
    "        print(f\"  Compression ratio: {compression_ratio:.2f}:1\")\n",
    "        print(f\"  Space savings: {(1 - compressed_size/original_size)*100:.1f}%\")\n",
    "        print(f\"  Quality (PSNR): {psnr:.2f} dB\")\n",
    "\n",
    "        # Create visualization figure\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "        # Original image\n",
    "        axes[0, 0].imshow(segment_image_cropped)\n",
    "        axes[0, 0].set_title(f'Original\\n{h}x{w} pixels')\n",
    "        axes[0, 0].axis('off')\n",
    "\n",
    "        # Add pixel info\n",
    "        non_black = np.sum(np.any(segment_image_cropped > 10, axis=2))\n",
    "        axes[0, 0].text(0.02, 0.98, f'Content: {non_black:,} px', \n",
    "                    transform=axes[0, 0].transAxes, fontsize=9, color='white',\n",
    "                    verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n",
    "\n",
    "        # Reconstructed image\n",
    "        reconstructed_img = reconstruction_result['image']\n",
    "        axes[0, 1].imshow(reconstructed_img)\n",
    "        axes[0, 1].set_title(f'Reconstructed\\n{n_colors} colors')\n",
    "        axes[0, 1].axis('off')\n",
    "\n",
    "        # Difference (amplified for visibility)\n",
    "        diff = np.abs(segment_image_cropped.astype(float) - reconstructed_img.astype(float))\n",
    "        diff_display = np.clip(diff * 3, 0, 255).astype(np.uint8)\n",
    "        axes[0, 2].imshow(diff_display)\n",
    "        axes[0, 2].set_title(f'Difference (Ã—3)\\nPSNR: {psnr:.2f} dB')\n",
    "        axes[0, 2].axis('off')\n",
    "\n",
    "        # Add MSE/PSNR to difference plot\n",
    "        mse = np.mean(diff ** 2)\n",
    "        axes[0, 2].text(0.02, 0.98, f'MSE: {mse:.2f}', \n",
    "                    transform=axes[0, 2].transAxes, fontsize=9, color='white',\n",
    "                    verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='red', alpha=0.7))\n",
    "\n",
    "        # Color palette visualization\n",
    "        palette = np.array(seg_compression['palette'])\n",
    "        axes[1, 0].axis('off')\n",
    "\n",
    "        # Create palette visualization\n",
    "        if n_colors > 0:\n",
    "            # Create a color swatch\n",
    "            palette_h = max(1, min(10, n_colors // 10))\n",
    "            palette_w = (n_colors + palette_h - 1) // palette_h\n",
    "            \n",
    "            palette_img = np.zeros((palette_h * 20, palette_w * 20, 3), dtype=np.uint8)\n",
    "            \n",
    "            for idx, color in enumerate(palette):\n",
    "                row = (idx // palette_w) * 20\n",
    "                col = (idx % palette_w) * 20\n",
    "                palette_img[row:row+18, col:col+18] = color\n",
    "            \n",
    "            # Display in inset axes\n",
    "            from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "            ax_inset = inset_axes(axes[1, 0], width=\"60%\", height=\"60%\", loc='center')\n",
    "            ax_inset.imshow(palette_img)\n",
    "            ax_inset.set_title(f'Color Palette ({n_colors} colors)')\n",
    "            ax_inset.axis('off')\n",
    "            \n",
    "            # Add palette stats\n",
    "            unique_original = len(np.unique(segment_image_cropped.reshape(-1, 3), axis=0))\n",
    "            palette_text = f'Original: {unique_original} colors\\nCompressed: {n_colors} colors\\nReduction: {(1 - n_colors/unique_original)*100:.1f}%'\n",
    "            axes[1, 0].text(0.5, 0.1, palette_text, transform=axes[1, 0].transAxes,\n",
    "                        fontsize=9, horizontalalignment='center',\n",
    "                        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))\n",
    "\n",
    "        # Compression statistics visualization\n",
    "        axes[1, 1].axis('off')\n",
    "\n",
    "        # Create bar chart for size comparison\n",
    "        size_data = [original_size, compressed_size]\n",
    "        size_labels = ['Original', 'Compressed']\n",
    "        colors = ['skyblue', 'lightcoral']\n",
    "\n",
    "        # Create inset axes for bar chart\n",
    "        ax_bar = inset_axes(axes[1, 1], width=\"60%\", height=\"60%\", loc='center')\n",
    "        bars = ax_bar.bar(size_labels, size_data, color=colors, alpha=0.7)\n",
    "        ax_bar.set_title('Size Comparison')\n",
    "        ax_bar.set_ylabel('Bytes')\n",
    "\n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax_bar.text(bar.get_x() + bar.get_width()/2., height + max(size_data)*0.05,\n",
    "                    f'{height:,}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "        # Add ratio text\n",
    "        ratio_text = f'Compression Ratio: {compression_ratio:.2f}:1\\nSavings: {(1 - compressed_size/original_size)*100:.1f}%'\n",
    "        axes[1, 1].text(0.5, 0.1, ratio_text, transform=axes[1, 1].transAxes,\n",
    "                    fontsize=9, horizontalalignment='center',\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.7))\n",
    "\n",
    "        # Index map visualization (shows which palette index each pixel uses)\n",
    "        axes[1, 2].axis('off')\n",
    "\n",
    "        # Get index map\n",
    "        index_map = np.array(seg_compression['indices']).reshape(h, w)\n",
    "\n",
    "        # Display index map as grayscale\n",
    "        ax_index = inset_axes(axes[1, 2], width=\"60%\", height=\"60%\", loc='center')\n",
    "        im = ax_index.imshow(index_map, cmap='viridis', aspect='auto')\n",
    "        ax_index.set_title('Index Map (Palette Indices)')\n",
    "        ax_index.axis('off')\n",
    "\n",
    "        # Add colorbar for index map\n",
    "        plt.colorbar(im, ax=ax_index, fraction=0.046, pad=0.04)\n",
    "\n",
    "        # Add index map stats\n",
    "        index_unique = len(np.unique(index_map))\n",
    "        axes[1, 2].text(0.5, 0.1, f'Unique indices: {index_unique}/{n_colors}',\n",
    "                    transform=axes[1, 2].transAxes,\n",
    "                    fontsize=9, horizontalalignment='center',\n",
    "                    bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "        # Main title\n",
    "        plt.suptitle(f'Segment {seg_idx+1}: Color Quantization Results\\nTop-left: {top_left_abs_row, top_left_abs_col}, Size: {h}x{w}', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # ==============================================\n",
    "        # 5. CONSOLE SUMMARY (CLEAN FORMAT)\n",
    "        # ==============================================\n",
    "        print(f\"\\nðŸ“Š COMPRESSION SUMMARY:\")\n",
    "        print(f\"   Original:    {original_size:>8,} bytes\")\n",
    "        print(f\"   Compressed:  {compressed_size:>8,} bytes\")\n",
    "        print(f\"   Ratio:       {compression_ratio:>8.2f}:1\")\n",
    "        print(f\"   Savings:     {(1 - compressed_size/original_size)*100:>7.1f}%\")\n",
    "        print(f\"   PSNR:        {psnr:>8.2f} dB\")\n",
    "        print(f\"   Palette:     {n_colors:>8} colors\")\n",
    "        print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c08e793",
   "metadata": {},
   "source": [
    "### Loading of the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79b67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from encoder.enhancer.clahe import get_enhanced_image\n",
    "\n",
    "image_name = \"images/png/Lenna.png\"\n",
    "image = cv2.imread(image_name)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(8, 6))  # Optional: Set figure size\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.title(\"Lenna Image (RGB)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4545a",
   "metadata": {},
   "source": [
    "### Region of Interest Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be4420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from encoder.ROI.edges import compute_local_density, suggest_automatic_threshold, get_edge_map\n",
    "from encoder.ROI.thin_regions2 import remove_thin_structures_optimized\n",
    "from encoder.ROI.small_regions import remove_small_regions, connect_nearby_pixels, connect_by_closing_fast\n",
    "from encoder.ROI.small_gaps import bridge_small_gaps, bridge_small_gaps_fast\n",
    "\n",
    "from encoder.ROI.roi import remove_small_noise_regions, detect_meaningful_borders, protect_border_regions, fill_closed_regions, extract_roi_nonroi,visualize_roi_nonroi_comparison\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "roi_quality=20\n",
    "nonroi_quality=10\n",
    "\n",
    "\n",
    "# Get edge and density maps\n",
    "edge_map = get_edge_map(image_rgb)\n",
    "edge_density = compute_local_density(edge_map, kernel_size=3)\n",
    "\n",
    "plt.imshow(edge_map)\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(edge_density)\n",
    "plt.show()\n",
    "\n",
    "# Variables used for ROI Detection\n",
    "density_threshold = suggest_automatic_threshold(edge_density, edge_map, method=\"mean\") / 100\n",
    "min_region_size= math.ceil( image_rgb.size / math.pow(10, math.ceil(math.log(image_rgb.size, 10))-3 ) ) \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Complete pipeline: filter edges by density, then unify regions, remove small regions.\n",
    "Returns ROI and non-ROI separately.\n",
    "\"\"\"\n",
    "\n",
    "# Get high-density borders\n",
    "high_density_mask = edge_density > density_threshold\n",
    "intensity_borders = edge_map.copy()\n",
    "intensity_borders[~high_density_mask] = 0\n",
    "\n",
    "# Convert to binary (0 and 255)\n",
    "binary_borders = (intensity_borders > 0).astype(np.uint8) * 255\n",
    "\n",
    "# Remove tgin structures and noise from the picture\n",
    "binary_thin_bordersless=remove_thin_structures_optimized(binary_borders, density_threshold=0.10, thinness_threshold=0.3, window_size=25, min_region_size=25) \n",
    "noiseless_binary_borders=remove_small_noise_regions(binary_thin_bordersless, min_size=75)\n",
    "\n",
    "# Connect Regions Close to each other\n",
    "pre_connected = connect_by_closing_fast(\n",
    "    noiseless_binary_borders,\n",
    "    connection_distance=5,\n",
    "    min_region_size=25\n",
    ")\n",
    "connected = bridge_small_gaps_fast(pre_connected, max_gap=100, density_threshold=0.2, local_window=15, regional_window=25)\n",
    "\n",
    "\n",
    "plot_border_stages(intensity_borders, binary_borders, \n",
    "                   binary_thin_bordersless, noiseless_binary_borders,\n",
    "                   pre_connected, connected) \n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Unify regions while respecting natural borders and directional context.\n",
    "\"\"\"\n",
    "\n",
    "# Ensure binary image is 0-255 uint8\n",
    "#if connected.max() <= 1:\n",
    "binary_image = (connected * 255).astype(np.uint8)\n",
    "\n",
    "denoised=binary_image\n",
    "\n",
    "# Detect strong borders using gradient\n",
    "border_mask = detect_meaningful_borders(denoised, sensitivity=0.5)\n",
    "\n",
    "# Protect borders from being unified\n",
    "protected_image = protect_border_regions(denoised, border_mask, kernel_size=15)\n",
    "\n",
    "# Bridge small gaps within regions (not across borders), fill small closed regions and remove the remainings\n",
    "bridged_image = bridge_small_gaps_fast(protected_image, max_gap=25, density_threshold=0.2, local_window=15, regional_window=25)\n",
    "closed_regions=fill_closed_regions(bridged_image, min_hole_size=10, max_hole_size=10000, connectivity=4)\n",
    "cleaned_image = remove_small_regions(closed_regions, min_size=5, remove_thin_lines=True, kernel_size=30)\n",
    "\n",
    "# Create region map\n",
    "region_map = (cleaned_image > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "plot_region_processing_pipeline(\n",
    "    denoised, \n",
    "    border_mask, \n",
    "    protected_image, \n",
    "    bridged_image, \n",
    "    closed_regions, \n",
    "    cleaned_image, \n",
    "    region_map\n",
    ")\n",
    "\n",
    "# Extract ROI and non-ROI\n",
    "roi_image, nonroi_image, roi_mask, nonroi_mask = extract_roi_nonroi(image_rgb, region_map)\n",
    "\n",
    "visualize_roi_nonroi_comparison(image_rgb, roi_image, nonroi_image, region_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b23a507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.ROI.roi import  extract_regions\n",
    "\n",
    "roi_regions, nonroi_regions = extract_regions(image_rgb, roi_mask, nonroi_mask)\n",
    "\n",
    "print(f\"Found {len(roi_regions)} ROI regions\")\n",
    "print(f\"Found {len(nonroi_regions)} non-ROI regions\")\n",
    "\n",
    "# Display some statistics\n",
    "print(\"\\nROI Regions (sorted by area):\")\n",
    "for i, region in enumerate(sorted(roi_regions, key=lambda x: x['area'], reverse=True)[:5]):\n",
    "    print(f\"  Region {i+1}: Area = {region['area']} pixels\")\n",
    "\n",
    "print(\"\\nNon-ROI Regions (sorted by area):\")\n",
    "for i, region in enumerate(sorted(nonroi_regions, key=lambda x: x['area'], reverse=True)[:5]):\n",
    "    print(f\"  Region {i+1}: Area = {region['area']} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6839041",
   "metadata": {},
   "source": [
    "### SubRegion Quantization\n",
    "In this phase we have the SLIC function applied to every region in order to find SubRegions. For each SubRegions we find its unique colors and we perform teh clustering based off the quality in order to reduce the colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.subregions.split_score import calculate_split_score, normalize_result\n",
    "from encoder.subregions.slic import visualize_split_analysis, enhanced_slic_with_texture, extract_slic_segment_boundaries\n",
    "from encoder.compression.clustering import compute_clustering_params,cluster_palette_colors_parallel, get_all_unique_colors\n",
    "from encoder.compression.merging import merge_region_components_simple, visualize_merged_result\n",
    "\n",
    "\n",
    "subregions_components=[]\n",
    "\n",
    "for i, region in enumerate(roi_regions):\n",
    "\n",
    "    region_components=[]\n",
    "    \n",
    "    # ==============================================\n",
    "    # 1. EXTRACT THE subregions\n",
    "    # ==============================================\n",
    "    minr, minc, maxr, maxc = region['bbox']\n",
    "    bbox_region = image_rgb[minr:maxr, minc:maxc]\n",
    "    bbox_mask = region['bbox_mask']  # Irregular region mask\n",
    "    region_image = bbox_region\n",
    "    \n",
    "    print(f\"Region {i+1}: {bbox_region.shape[1]}x{bbox_region.shape[0]} pixels\")\n",
    "    print(f\"Mask area: {np.sum(bbox_mask):,} pixels\")\n",
    "\n",
    "    \n",
    "    # ==============================================\n",
    "    # 2. ANALYZE REGION FOR SEGMENTATION\n",
    "    # ==============================================\n",
    "    overall_score, color_score, texture_score = calculate_split_score(bbox_region, bbox_mask)\n",
    "    \n",
    "    print(f\"  Analysis scores:\")\n",
    "    print(f\"    Overall: {overall_score:.3f}\")\n",
    "    print(f\"    Color: {color_score:.3f}\")\n",
    "    print(f\"    Texture: {texture_score:.3f}\")\n",
    "    \n",
    "    window = math.ceil(math.ceil(math.log(bbox_region.size, 10)) * math.log(bbox_region.size))\n",
    "    normalized_overall_score = normalize_result(overall_score, window)\n",
    "    optimal_segments = math.ceil(normalized_overall_score)\n",
    "    \n",
    "    if optimal_segments <= 0: \n",
    "        optimal_segments = 1\n",
    "    \n",
    "    \n",
    "    print(f\"  Optimal segments: {optimal_segments}\")\n",
    "    \n",
    "    # ==============================================\n",
    "    # 3. APPLY SLIC SEGMENTATION TO THE subregions\n",
    "    # ==============================================\n",
    "    if optimal_segments<1: optimal_segments=1\n",
    "    subregions_segments, texture_map = enhanced_slic_with_texture(bbox_region, bbox_mask, n_segments=optimal_segments)\n",
    "    segment_boundaries = extract_slic_segment_boundaries(subregions_segments, bbox_mask)\n",
    "\n",
    "    print(f\"  Found {len(segment_boundaries)} sub-regions\")\n",
    "    print(f\"  Total boundary points: {sum(seg['num_points'] for seg in segment_boundaries):,}\")\n",
    "\n",
    "    plot_subregions(bbox_region,bbox_mask,subregions_segments,segment_boundaries)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for seg_idx, seg_data in enumerate(segment_boundaries):\n",
    "        segment_id = seg_data.get('segment_id', seg_idx)\n",
    "        segment_mask = (subregions_segments == segment_id) & bbox_mask\n",
    "        \n",
    "        import numpy as np\n",
    "        segment_pixels = np.sum(segment_mask)\n",
    "        \n",
    "        print(f\"\\n    Segment {seg_idx+1}/{len(segment_boundaries)} (ID: {segment_id}):\")\n",
    "        print(f\"      Pixels: {segment_pixels:,}\")\n",
    "        \n",
    "        # ==============================================\n",
    "        # 1. CREATE CORRECT SEGMENT IMAGE\n",
    "        # ==============================================\n",
    "        \n",
    "        # Get the ORIGINAL pixels for this segment only\n",
    "        segment_pixels_original = region_image[segment_mask]\n",
    "        \n",
    "        # ==============================================\n",
    "        # 2. FIND TIGHT BOUNDING BOX FROM SEGMENT MASK\n",
    "        # ==============================================\n",
    "        # Use the SEGMENT MASK, not the modified image!\n",
    "        rows, cols = np.where(segment_mask)\n",
    "        \n",
    "        if len(rows) == 0 or len(cols) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Find bounding box coordinates FROM THE MASK\n",
    "        min_row, max_row = rows.min(), rows.max()\n",
    "        min_col, max_col = cols.min(), cols.max()\n",
    "        \n",
    "        # Add small padding\n",
    "        pad = 2\n",
    "        h, w = region_image.shape[:2]\n",
    "        min_row = max(0, min_row - pad) \n",
    "        max_row = min(h - 1, max_row + pad) \n",
    "        min_col = max(0, min_col - pad)\n",
    "        max_col = min(w - 1, max_col + pad)\n",
    "        \n",
    "        # Calculate dimensions\n",
    "        crop_height = max_row - min_row + 1\n",
    "        crop_width = max_col - min_col + 1\n",
    "        \n",
    "        # ==============================================\n",
    "        # 3. CROP ORIGINAL IMAGE TO BBOX\n",
    "        # ==============================================\n",
    "        # Crop the ORIGINAL region image (not modified)\n",
    "        bbox_crop = region_image[min_row:max_row+1, min_col:max_col+1]\n",
    "        \n",
    "        # Also crop the segment mask to same bbox\n",
    "        segment_mask_cropped = segment_mask[min_row:max_row+1, min_col:max_col+1]\n",
    "        \n",
    "        # Create final segment image: only segment pixels visible\n",
    "        segment_image_cropped = np.zeros_like(bbox_crop)\n",
    "        segment_image_cropped[segment_mask_cropped] = bbox_crop[segment_mask_cropped]\n",
    "        \n",
    "        # ==============================================\n",
    "        # 4. CALCULATE ABSOLUTE COORDINATES\n",
    "        # ==============================================            \n",
    "        absolute_min_row = min_row + minr\n",
    "        absolute_min_col = min_col + minc \n",
    "        absolute_max_row = max_row + minr \n",
    "        absolute_max_col = max_col + minc\n",
    "        \n",
    "        top_left_abs_row = absolute_min_row\n",
    "        top_left_abs_col = absolute_min_col\n",
    "        \n",
    "        print(f\"      Original region shape: {region_image.shape[:2]}\")\n",
    "        print(f\"      Cropped bbox shape: {segment_image_cropped.shape[:2]}\")\n",
    "        print(f\"      Segment pixels in crop: {np.sum(segment_mask_cropped)}\")\n",
    "        print(f\"      Top-left in full image: ({top_left_abs_row}, {top_left_abs_col})\")\n",
    "\n",
    "\n",
    "        # Get segment pixels\n",
    "        segment_pixels = bbox_crop[segment_mask_cropped]\n",
    "\n",
    "        if len(segment_pixels) > 0:\n",
    "            # Check for black pixels INSIDE the segment (not background)\n",
    "            black_in_segment = np.any(np.all(segment_pixels == [0, 0, 0], axis=1))\n",
    "            \n",
    "            if black_in_segment:\n",
    "                print(f\"Segment {segment_id}: Has black pixels inside segment\")\n",
    "                \n",
    "                # Replace black pixels with nearest non-black color\n",
    "                # First, find non-black pixels\n",
    "                non_black_mask = ~np.all(segment_pixels == [0, 0, 0], axis=1)\n",
    "                non_black_pixels = segment_pixels[non_black_mask]\n",
    "                \n",
    "                if len(non_black_pixels) > 0:\n",
    "                    # For each black pixel, find closest non-black color\n",
    "                    black_mask = np.all(segment_pixels == [0, 0, 0], axis=1)\n",
    "                    black_indices = np.where(black_mask)[0]\n",
    "                    \n",
    "                    for idx in black_indices:\n",
    "                        # Calculate distances to all non-black pixels\n",
    "                        distances = np.linalg.norm(non_black_pixels - segment_pixels[idx], axis=1)\n",
    "                        closest_idx = np.argmin(distances)\n",
    "                        segment_pixels[idx] = non_black_pixels[closest_idx]\n",
    "                    \n",
    "                    print(f\"  Fixed {len(black_indices)} black pixels in segment\")\n",
    "                \n",
    "                # Update the segment image\n",
    "                segment_image_cropped[segment_mask_cropped] = segment_pixels\n",
    "\n",
    "        # ==============================================\n",
    "        # 2. COMPRESS CROPPED SEGMENT\n",
    "        # ==============================================\n",
    "        seg_compression = get_all_unique_colors(\n",
    "            segment_image_cropped,\n",
    "            (top_left_abs_row, top_left_abs_col)\n",
    "        )\n",
    "\n",
    "        n_colors = seg_compression['actual_colors']\n",
    "\n",
    "        palette_colors = np.array(seg_compression['palette'])\n",
    "        \n",
    "        # Option A: Simple improved formulas\n",
    "        eps, min_samples, max_colors_per_cluster = compute_clustering_params(\n",
    "            n_colors, roi_quality, color_space='lab'\n",
    "        )\n",
    "\n",
    "        \n",
    "\n",
    "        # Then cluster the colors\n",
    "        seg_compression = cluster_palette_colors_parallel(\n",
    "            roi_quality,\n",
    "            seg_compression,\n",
    "            eps=eps,           # Distance threshold (0-255 scale)\n",
    "            min_samples=1,      # Min colors to form cluster\n",
    "            max_colors_per_cluster=max_colors_per_cluster  # Split large clusters\n",
    "        )\n",
    "\n",
    "        \n",
    "        print(f\"Eps: {eps}\")\n",
    "        print(f\"n_colors: {n_colors}\")\n",
    "        print(f\"max_colors_per_cluster: {max_colors_per_cluster}\")\n",
    "\n",
    "        \n",
    "        #show_reconstruction(seg_compression, seg_idx,segment_image_cropped,top_left_abs_row,top_left_abs_col)\n",
    "\n",
    "        region_components.append(seg_compression)\n",
    "            \n",
    "        \n",
    "            \n",
    "\n",
    "        #all_segments_compressed.append(seg_compression)\n",
    "        region_components.append(seg_compression)\n",
    "\n",
    "\n",
    "    # ==============================================\n",
    "    # 4. MERGE COMPONENTS WITHIN THIS subregions\n",
    "    # ==============================================\n",
    "    if len(region_components) > 1:\n",
    "        # Get subregions bbox\n",
    "        minr, minc, maxr, maxc = region['bbox']\n",
    "        subregions_bbox = (minr, minc, maxr, maxc)\n",
    "        subregions_height = maxr - minr\n",
    "        subregions_width = maxc - minc\n",
    "        \n",
    "        # Choose merging strategy\n",
    "        # Simple merge (colored pixels override black)\n",
    "        merged_components = merge_region_components_simple(region_components, subregions_bbox)\n",
    "        subregions_components.append(merged_components)\n",
    "\n",
    "        visualize_merged_result(merged_components, (subregions_height, subregions_width), minr, minc)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        original_pixels = sum(seg['shape'][0] * seg['shape'][1] for seg in region_components)\n",
    "        original_black = sum(seg['indices'].count(1) for seg in region_components)\n",
    "        \n",
    "        merged_pixels = sum(seg['shape'][0] * seg['shape'][1] for seg in merged_components)\n",
    "        merged_black = sum(seg['indices'].count(1) for seg in merged_components)\n",
    "        \n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"  Original: {len(region_components)} segments, {original_pixels:,} pixels\")\n",
    "        print(f\"  Merged: {len(merged_components)} segments, {merged_pixels:,} pixels\")\n",
    "        print(f\"  Black reduction: {original_black - merged_black:,} pixels\")\n",
    "        print(f\"  Pixel reduction: {original_pixels - merged_pixels:,} pixels\")\n",
    "        \n",
    "    else:\n",
    "        # Just add the single component\n",
    "        subregions_components.append(region_components)\n",
    "        print(f\"Only 1 component in subregions {i+1}, no merging needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daaf3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.compression.subregions import subregion_quantization\n",
    "#Emulate teh behaviour for next computation\n",
    "ROI_subregions_components=subregion_quantization(image_rgb, roi_regions, quality=roi_quality, subregion_type=\"ROI\", debug=False)\n",
    "nonROI_subregions_components=subregion_quantization(image_rgb, nonroi_regions, quality=nonroi_quality, subregion_type=\"nonROI\", debug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf24aa2",
   "metadata": {},
   "source": [
    "### Region Clustering\n",
    "This is the second phase of the Hierarchical clustering. Clustering colors between each ROI / nonROI.\n",
    "The same approach from before is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd6e194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.compression.regions import region_quantization\n",
    "\n",
    "roi_region_quality=roi_quality*2\n",
    "nonroi_region_quality=nonroi_quality*2\n",
    "\n",
    "if roi_region_quality>100: roi_region_quality=100\n",
    "if nonroi_region_quality>100: nonroi_region_quality=100\n",
    "\n",
    "original_image_height, original_image_width, _ = image_rgb.shape\n",
    "\n",
    "try: roi_components=region_quantization(ROI_subregions_components, quality=roi_region_quality, original_image_height=original_image_height, original_image_width=original_image_width)\n",
    "except: roi_components=[]\n",
    "\n",
    "try: nonroi_components=region_quantization(nonROI_subregions_components, quality=nonroi_region_quality, original_image_height=original_image_height, original_image_width=original_image_width)\n",
    "except: nonroi_components=[]\n",
    "\n",
    "image_components=roi_components+nonroi_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab923b6e",
   "metadata": {},
   "source": [
    "### Image Quantization\n",
    "Same process is applied to the last step of the clustering. Here we cluster the colors of all the regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e16a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.compression.image import quantize_image\n",
    "\n",
    "image_quality=roi_region_quality+nonroi_region_quality\n",
    "if image_quality>100: image_quality=100\n",
    "\n",
    "image_seg_compression=quantize_image(image_components, quality=image_quality, original_image_height=original_image_height, original_image_width=original_image_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b190a",
   "metadata": {},
   "source": [
    "### Saving the compression\n",
    "In order to perform the compression, we compress the palette of colors and all the matrix of indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23182e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder.compression.compression import save_compressed, compress_palette, compress_indices_simple_optimized\n",
    "\n",
    "filename=\"images/rhccq_20_10/kauai_compressed.rhccq\"\n",
    "\n",
    "\n",
    "def lossless_compress_optimized(palette, indices_list, shape, use_manual_rle=False):\n",
    "    \"\"\"\n",
    "    Optimized compression with automatic dtype selection.\n",
    "    Handles both Python lists and numpy arrays.\n",
    "    \"\"\"\n",
    "    # Compress palette\n",
    "    palette_compressed = compress_palette(palette)\n",
    "    \n",
    "    # Handle different input types\n",
    "    if isinstance(indices_list, np.ndarray):\n",
    "        # It's a numpy array\n",
    "        if indices_list.size == 0:\n",
    "            max_index = 0\n",
    "            indices_flat = indices_list.flatten()\n",
    "        else:\n",
    "            max_index = indices_list.max()\n",
    "            indices_flat = indices_list.flatten()\n",
    "    elif isinstance(indices_list, list):\n",
    "        # It's a Python list\n",
    "        if not indices_list:\n",
    "            max_index = 0\n",
    "            indices_flat = indices_list\n",
    "        else:\n",
    "            max_index = max(indices_list)\n",
    "            indices_flat = indices_list\n",
    "    else:\n",
    "        raise TypeError(f\"indices_list must be list or numpy array, got {type(indices_list)}\")\n",
    "    \n",
    "    # Determine optimal dtype for indices\n",
    "    if max_index < 256:\n",
    "        dtype = np.uint8\n",
    "        dtype_name = 'uint8'\n",
    "    elif max_index < 65536:\n",
    "        dtype = np.uint16\n",
    "        dtype_name = 'uint16'\n",
    "    else:\n",
    "        dtype = np.uint32\n",
    "        dtype_name = 'uint32'\n",
    "    \n",
    "    print(f\"Indices optimization: max={max_index}, using {dtype_name}\")\n",
    "    \n",
    "    indices_compressed = compress_indices_simple_optimized(indices_flat, dtype)\n",
    "    method = 'zlib_direct'\n",
    "    \n",
    "    return {\n",
    "        's': shape,\n",
    "        'l': len(palette),\n",
    "        'p': palette_compressed,\n",
    "        'i': indices_compressed,\n",
    "        'd': dtype_name,  # Store dtype for decompression\n",
    "        #'method': method\n",
    "    }\n",
    "\n",
    "\n",
    "# Get your final data\n",
    "final_data = image_seg_compression  # or clustered_result\n",
    "\n",
    "# Extract components\n",
    "shape = final_data['shape']\n",
    "palette = final_data['palette']\n",
    "indices_flat = final_data['indices']\n",
    "\n",
    "# Convert to matrix\n",
    "h, w = shape\n",
    "indices_matrix = np.array(indices_flat).reshape(h, w)\n",
    "\n",
    "print(f\"Compressing: {w}x{h} image, {len(palette)} colors\")\n",
    "\n",
    "# Compress\n",
    "from encoder.compression.compression import save_compressed\n",
    "\n",
    "compressed_data = lossless_compress_optimized(palette, indices_matrix, shape)\n",
    "\n",
    "# Save\n",
    "file_size = save_compressed(compressed_data, filename)\n",
    "\n",
    "# Stats\n",
    "original_size = h * w * 3\n",
    "compression_ratio = original_size / file_size\n",
    "\n",
    "print(f\"âœ… Saved: {filename}\")\n",
    "print(f\"   Original: {original_size:,} bytes\")\n",
    "print(f\"   Compressed: {file_size:,} bytes\")\n",
    "print(f\"   Ratio: {compression_ratio:.2f}:1\")\n",
    "print(f\"   Savings: {(1 - file_size/original_size)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4616e",
   "metadata": {},
   "source": [
    "### Comparison of the Compressed picture with the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70c233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decoder.uncompression.uncompression import lossless_decompress, load_compressed, decompress_color_quantization\n",
    "from decoder.uncompression.comparison import calculate_quality_metrics, create_difference_visualization, print_quality_report, plot_comparison, calculate_adaptive_quality_metrics, print_adaptive_metrics\n",
    "\n",
    "original=image_rgb\n",
    "\n",
    "# Load and decompress\n",
    "loaded = load_compressed(filename)\n",
    "compressed=lossless_decompress(loaded)\n",
    "palette_restored, indices_restored, shape_restored = lossless_decompress(loaded)\n",
    "\n",
    "debug=False\n",
    "if debug:\n",
    "    print(\"\\nDecompressed data:\")\n",
    "    print(f\"Palette: {palette_restored}\")\n",
    "    print(f\"Indices: {indices_restored}\")\n",
    "    print(f\"Shape: {shape_restored}\")\n",
    "\n",
    "\n",
    "reconstruction_result = decompress_color_quantization(compressed)\n",
    "reconstructed = reconstruction_result['image']  # This is a numpy array\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"reconstructed\")\n",
    "plt.imshow(reconstructed)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"\\nImage sizes:\")\n",
    "print(f\"  Original: {original.shape[1]}x{original.shape[0]}\")\n",
    "print(f\"  Reconstructed: {reconstructed.shape[1]}x{reconstructed.shape[0]}\")\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"\\nCalculating quality metrics...\")\n",
    "metrics=calculate_adaptive_quality_metrics(original, reconstructed)\n",
    "\n",
    "# Create difference visualizations\n",
    "print(\"Creating difference visualizations...\")\n",
    "differences = create_difference_visualization(original, reconstructed)\n",
    "\n",
    "# Print report\n",
    "#print_quality_report(metrics)\n",
    "print_adaptive_metrics(metrics, original.shape)\n",
    "\n",
    "\n",
    "metrics = calculate_quality_metrics(original, reconstructed)\n",
    "# Create comprehensive plot\n",
    "print(\"\\nGenerating comparison visualization...\")\n",
    "plot_comparison(original, reconstructed, metrics, differences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
